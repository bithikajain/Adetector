{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training NN models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import joblib\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from DataGenerator import DataGenerator_Sup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of all files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ad_folder = '../Data/audio_ads' # positive samples location\n",
    "Music_folder = '../Data/Music'  # negative samples (music) location\n",
    "Podcast_folder = '../Data/pod'  # negative samples (podcasts) location\n",
    "\n",
    "pos_files = []\n",
    "for r,d,f in os.walk(Ad_folder):\n",
    "    for filename in f:\n",
    "        if '.mp3' in filename:\n",
    "            pos_files.append(os.path.join(Ad_folder,filename))\n",
    "\n",
    "music_files = []\n",
    "for r,d,f in os.walk(Music_folder):\n",
    "    for filename in f:\n",
    "        if '.mp3' or '.au' in filename:\n",
    "            music_files.append(os.path.join(r,filename))\n",
    "\n",
    "podcast_files = []\n",
    "for r,d,f in os.walk(Podcast_folder):\n",
    "    for filename in f:\n",
    "        if '.wav' in filename:\n",
    "            podcast_files.append(os.path.join(r,filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many mp3 files do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2303 positive examples\n",
      "We have 1023 music examples\n",
      "We have 1567 podcast examples\n",
      "--------------------------------\n",
      "In total, 1151.5 minutes of positive and 824.9 minutes of negative\n",
      "A factor of 0.72 is applied on positives for balancing\n"
     ]
    }
   ],
   "source": [
    "neg_files = music_files + podcast_files\n",
    "n_pos_files = len(pos_files)\n",
    "n_neg_files = len(neg_files)\n",
    "\n",
    "print('We have ' + str(n_pos_files) + ' positive examples')\n",
    "print('We have ' + str(len(music_files)) + ' music examples')\n",
    "print('We have ' + str(len(podcast_files)) + ' podcast examples')\n",
    "\n",
    "music_duration = 30/60.0 # duration of files in minutes\n",
    "podcast_duration = 12/60.0 # duration of files in minutes\n",
    "ads_duration = 30/60.0 # average duration of ad files in minutes\n",
    "\n",
    "pos_minutes = round(ads_duration*n_pos_files,2)\n",
    "neg_minutes = round(music_duration*len(music_files) + podcast_duration*len(podcast_files),2)\n",
    "pos_fraction = str(round(neg_minutes/pos_minutes,2)) # the fraction of positives to take for balancing\n",
    "print('--------------------------------')\n",
    "print('In total, ' + str(pos_minutes) + ' minutes of positive and ' + str(neg_minutes) + ' minutes of negative')\n",
    "print('A factor of ' + str(pos_fraction) + ' is applied on positives for balancing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_features):\n",
    "    '''Create a model obejct with an input of length n_features'''\n",
    "    model = Sequential() # create a model instance\n",
    "\n",
    "    #add model layers\n",
    "    model.add(Dense(256, activation = 'relu', input_shape=(n_features,)))\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time in minutes for positive/negative is 618.67\n",
      "Out of this value, 309.335 is music and 309.335 is podcasts\n",
      "---------------------------------------------------------------\n",
      "This translates into 618 files of music and 1546 files of podcasts for training\n",
      "The rest of the negative files are used for testing\n",
      "---------------------------------------------------------------\n",
      "1243 poitive files are used for training\n",
      "414 poitive files are used for testing\n"
     ]
    }
   ],
   "source": [
    "pos_fraction = 0.72 # the fraction of positives used in training\n",
    "train_fraction = 0.75 # the fraction of the data used for training\n",
    "\n",
    "train_minutes = round(train_fraction*neg_minutes,2) # number of neg audio training minutes\n",
    "train_music_minutes = train_minutes/2 # number of minutes for music training\n",
    "train_podcast_minutes = train_minutes/2 # number of minutes for podcast training\n",
    "print('Training time in minutes for positive/negative is ' + str(train_minutes))\n",
    "print('Out of this value, ' + str(train_music_minutes) + ' is music and ' \n",
    "      + str(train_podcast_minutes) +' is podcasts')\n",
    "\n",
    "n_train_music_files = int(train_music_minutes/music_duration)\n",
    "n_train_podcast_files = int(train_podcast_minutes/podcast_duration)\n",
    "n_train_pos_files = int(n_pos_files*pos_fraction*train_fraction)\n",
    "n_test_pos_files = int(n_pos_files*pos_fraction*(1-train_fraction))\n",
    "print('---------------------------------------------------------------')\n",
    "print('This translates into ' + str(n_train_music_files) + ' files of music'\n",
    "      + ' and ' + str(n_train_podcast_files) + ' files of podcasts for training')\n",
    "print('The rest of the negative files are used for testing')\n",
    "print('---------------------------------------------------------------')\n",
    "print(str(n_train_pos_files) + ' poitive files are used for training')\n",
    "print(str(n_test_pos_files) + ' poitive files are used for testing')\n",
    "\n",
    "assert len(music_files) >= n_train_music_files, 'There are not enough music files for that!'\n",
    "assert len(podcast_files) >= n_train_podcast_files, 'There are not enough podcast files for that!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = [] # a list of training files \n",
    "test_files = [] # a list of test files \n",
    "\n",
    "# shuffle files\n",
    "np.random.shuffle(pos_files)\n",
    "np.random.shuffle(music_files)\n",
    "np.random.shuffle(podcast_files)\n",
    "\n",
    "'''Collect a balanced list of files + add labels'''\n",
    "# Training list\n",
    "for f in pos_files[:n_train_pos_files]:\n",
    "    train_files.append([f,1])\n",
    "for f in music_files[:n_train_music_files]:\n",
    "    train_files.append([f,0])\n",
    "for f in podcast_files[:n_train_podcast_files]:\n",
    "    train_files.append([f,0])\n",
    "\n",
    "# Test list\n",
    "for f in pos_files[n_train_pos_files:n_train_pos_files + n_test_pos_files]:\n",
    "    train_files.append([f,1])\n",
    "for f in music_files[n_train_music_files:]:\n",
    "    train_files.append([f,0])\n",
    "for f in podcast_files[n_train_podcast_files:]:\n",
    "    train_files.append([f,0])\n",
    "\n",
    "train_generator = DataGenerator_Sup(train_files, dataset='train')\n",
    "test_generator = DataGenerator_Sup(test_files, dataset='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 1690)\n",
      "(52, 1)\n",
      "Positive example fraction in batch is 0.5192307692307693\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    X, Y = train_generator.__getitem__(2) # get item\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    print('Positive example fraction in batch is ' + str((sum(Y == 1)/Y.shape[0])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train NN model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and compile model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 1690\n",
    "model = create_model(num_features)\n",
    "filepath = 'models/weights_1690_256_64_1_with_pod.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "H = model.fit_generator(generator = train_generator, epochs = 2, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.figure(figsize= (10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(H.history['loss'], linewidth=3, color = 'b')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(H.history['acc'], linewidth=3, color = 'g')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error files:\n",
    "train_generatorerator.err_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate a model for evaluation\n",
    "num_features = 1690\n",
    "eval_model = create_model(num_features)\n",
    "# load weights\n",
    "eval_model.load_weights('models/weights_1690_256_64_1.hdf5')\n",
    "# compile\n",
    "eval_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What metrics do we use for evaluation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the model perform on the test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model.evaluate_generator(generator = test_generator, steps = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
