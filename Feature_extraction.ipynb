{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of all files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3_folder = '../Data/audio_ads' # audion files location\n",
    "\n",
    "files = []\n",
    "for r,d,f in os.walk(mp3_folder):\n",
    "    for filename in f:\n",
    "        if '.mp3' in filename:\n",
    "            files.append(os.path.join(mp3_folder,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many mp3 files do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2307"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clips(filepath_list, d = 3, sr = 22050):\n",
    "    '''Loads files in filepath_list, cuts them to clips of length\n",
    "       d and returns a list of all the clips'''\n",
    "    clip_list = []\n",
    "    # load all files in filepath_list\n",
    "    for f in filepath_list:\n",
    "        i = 0 # keep track of clip number\n",
    "        audio = librosa.core.load(f, offset = i*d, duration = d)[0]\n",
    "        # add to data_list only clips in standard size\n",
    "        while(len(audio) == sr*d):\n",
    "            clip_list.append(audio)\n",
    "            i = i+1\n",
    "            audio = librosa.core.load(f, offset = i*d, duration = d)[0]\n",
    "    \n",
    "    return clip_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clips2features(clip_list, n_mfcc = 13, sr = 22050, train_size = 0.8):\n",
    "    '''Takes a list of equal length clips with rate sr, \n",
    "       and returns feture vector with n_mfcc frequency coefficients'''\n",
    "    feature_vectors = []\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    n_clips = len(clip_list)\n",
    "    n_train = int(np.floor(n_clips*train_size))\n",
    "    np.random.shuffle(clip_list) # randomize data\n",
    "    # extract feature vectors and append to feature_vectors list \n",
    "    for clip in clip_list:\n",
    "        features = librosa.feature.mfcc(clip, sr=sr, n_mfcc=n_mfcc, dct_type=2)\n",
    "        feature_vectors.append(features.flatten())\n",
    "    # divide train and test\n",
    "    X_train = feature_vectors[:n_train]\n",
    "    X_test = feature_vectors[n_train:]\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kmeans(X_train, n_clusters = 100):\n",
    "    '''Takes a list of feature vectors and trains \n",
    "       a k-means model'''\n",
    "    X = np.vstack(X_train) # stack vertically (#samples, #features)\n",
    "    # normalize\n",
    "    mu = np.mean(X, axis=0) \n",
    "    std = np.std(X, axis=0)\n",
    "    X = (X-mu)/std\n",
    "    # create and train model\n",
    "    model = KMeans(n_clusters=n_clusters)\n",
    "    model.fit(X)\n",
    "    \n",
    "    return model,mu,std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and train k-means model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "859"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = clips2features(load_clips(files[:110]))\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, mu, std = train_kmeans(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1690)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test performance on not seen ads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[80.53090468, 40.54711136, 52.58741733, 50.16121711, 56.47006932,\n",
       "        68.84435732, 41.55130108, 49.31517079, 46.21020695, 44.42434862,\n",
       "        64.52468175, 42.78968302, 45.55043281, 40.83980678, 44.16459565,\n",
       "        72.9480642 , 58.75859626, 57.5317853 , 47.36817177, 39.39728575,\n",
       "        55.09598456, 63.76115656, 46.39515206, 55.7892186 , 55.98650091,\n",
       "        42.00257581, 60.68926519, 55.71863634, 42.85679997, 61.58421043,\n",
       "        45.12394223, 58.09512382, 59.17163381, 52.63224123, 60.18193088,\n",
       "        49.2689304 , 62.14131758, 60.00975938, 41.31073127, 53.26580044,\n",
       "        46.87035554, 40.82545742, 64.31951857, 44.48699632, 47.55314113,\n",
       "        66.75964575, 42.62382876, 41.42230213, 50.30348067, 53.47969981,\n",
       "        68.39748796, 56.28960579, 44.20823699, 79.49228486, 61.07018167,\n",
       "        67.04444223, 53.68837932, 42.9568288 , 54.40175159, 61.40513008,\n",
       "        50.58325271, 56.47279949, 57.1112798 , 53.12897571, 58.84455267,\n",
       "        48.181523  , 63.91576358, 58.08671884, 62.87358398, 63.30473701,\n",
       "        58.77016101, 51.46877719, 66.79374671, 65.84834515, 59.06826027,\n",
       "        42.27454525, 40.61490437, 59.26901746, 58.69483632, 67.06232304,\n",
       "        55.1183501 , 69.56844936, 60.33759134, 49.99326968, 62.62644021,\n",
       "        60.77394635, 66.70421259, 41.13445665, 62.66076858, 43.90727245,\n",
       "        68.17995155, 63.14399286, 59.13141708, 62.49233421, 53.60851936,\n",
       "        53.60804153, 62.00040236, 45.54445693, 57.17393508, 61.70699038],\n",
       "       [72.35426116, 36.78438819, 48.43368774, 48.79610238, 49.78928961,\n",
       "        63.38229125, 43.68052618, 47.01776202, 47.23017782, 39.34234957,\n",
       "        59.84384644, 40.63217492, 46.31412111, 36.19229457, 42.11588274,\n",
       "        66.07895608, 59.40218243, 53.54307738, 43.02213634, 37.17606765,\n",
       "        49.67876337, 62.63005605, 44.6138955 , 54.1572208 , 55.36428352,\n",
       "        37.67623615, 57.78830418, 53.78683827, 42.30666858, 59.35628626,\n",
       "        44.94183544, 58.03558568, 61.05657313, 53.26510783, 58.14296636,\n",
       "        49.39559797, 61.93651404, 56.84726859, 39.73082373, 54.95723328,\n",
       "        45.08882526, 37.29364088, 59.52810799, 38.40078225, 48.74856668,\n",
       "        65.62379791, 41.81969974, 41.95217553, 52.65090909, 54.94511211,\n",
       "        62.3854792 , 57.63500034, 41.27426507, 71.43723835, 61.14862897,\n",
       "        62.48758626, 53.52474506, 42.02028633, 54.88977821, 55.30489467,\n",
       "        49.71699798, 55.83021557, 59.68562927, 52.71709498, 62.60779044,\n",
       "        49.9806494 , 53.7348475 , 57.05525685, 61.30528755, 56.41833591,\n",
       "        56.97975994, 52.94294571, 63.79414419, 60.57897242, 55.58130024,\n",
       "        36.95307581, 40.67314454, 61.71507212, 60.50299651, 62.12074158,\n",
       "        53.87075693, 62.49233504, 57.19064964, 49.43999391, 61.23981219,\n",
       "        55.64363792, 64.08087387, 39.79694189, 61.07055981, 41.42178553,\n",
       "        65.11907522, 58.18788614, 58.17403318, 58.8519907 , 53.41669878,\n",
       "        60.44132266, 57.93608667, 45.41795737, 57.58439036, 57.87724678]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = (np.vstack(X_test[:2])-mu)/std\n",
    "model.transform(X_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Music smaple (Negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Music_folder = '../Data/Music' # audion files location\n",
    "\n",
    "Music_files = []\n",
    "for r,d,f in os.walk(Music_folder):\n",
    "    for filename in f:\n",
    "        if '.mp3' in filename:\n",
    "            Music_files.append(os.path.join(Music_folder,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Music = clips2features(load_clips(Music_files), train_size=1)[0]\n",
    "len(X_Music)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model performance on non seen music:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70.81090267, 28.80918075, 44.49385676, 38.03492597, 43.83396361,\n",
       "        57.2433692 , 32.03460256, 41.2550844 , 40.37259678, 36.01761123,\n",
       "        56.99219876, 31.41292297, 45.96115588, 27.37115503, 35.09680603,\n",
       "        62.90780558, 51.12377287, 50.76941471, 34.6424082 , 28.26810225,\n",
       "        47.56678979, 54.17455897, 39.27687688, 50.15557896, 54.09416976,\n",
       "        27.31895072, 50.99221248, 48.13273594, 33.96282486, 53.75906538,\n",
       "        35.43247967, 54.22293607, 52.68654123, 44.36674475, 49.51456822,\n",
       "        41.21489622, 55.19398775, 53.90020253, 33.67307661, 42.91038013,\n",
       "        37.62601568, 28.52698261, 54.86042192, 26.47856216, 48.70965692,\n",
       "        53.85052906, 31.03596446, 32.66804539, 48.401807  , 45.94155756,\n",
       "        60.85826944, 48.10323273, 34.15038235, 68.86415089, 54.73230814,\n",
       "        59.85215025, 47.2651244 , 30.38489835, 48.60186392, 52.20325818,\n",
       "        40.45105611, 48.28066868, 48.74253611, 41.81015315, 53.53504803,\n",
       "        41.16957246, 52.92733624, 49.33272503, 51.15491618, 51.18260331,\n",
       "        48.50530151, 45.08405613, 62.54861842, 54.61138976, 50.00683415,\n",
       "        32.55509638, 32.21597358, 66.2359076 , 53.50214767, 54.1626893 ,\n",
       "        46.55052982, 63.01109002, 53.0655059 , 41.61655754, 54.80119873,\n",
       "        51.5817136 , 64.13149671, 37.65143614, 50.99771073, 34.48187495,\n",
       "        63.60732874, 55.32935811, 51.70606867, 54.48135231, 44.98261939,\n",
       "        51.99000698, 54.15447061, 44.37863383, 47.48629337, 53.21453555],\n",
       "       [65.42759126, 25.51784145, 42.93738676, 41.28960564, 40.37702559,\n",
       "        53.58550624, 31.58110422, 41.38508932, 39.98815014, 29.19653117,\n",
       "        56.65953034, 31.38040676, 43.59607243, 24.78894534, 34.0080085 ,\n",
       "        57.78338222, 53.67001247, 48.42934272, 34.18728693, 25.15240535,\n",
       "        47.08227646, 55.68441218, 35.28274614, 48.66711541, 50.40158766,\n",
       "        24.75973156, 50.757256  , 49.56200646, 33.43756447, 51.6499483 ,\n",
       "        34.75047051, 54.4378917 , 53.75037592, 47.63224555, 51.62130188,\n",
       "        40.07222986, 54.6747347 , 53.5440763 , 31.44253522, 44.86700616,\n",
       "        37.59812709, 25.01136408, 52.23511741, 23.67941492, 43.82852791,\n",
       "        56.67870694, 31.77103978, 32.48624406, 48.23981664, 47.46762217,\n",
       "        61.02815589, 48.42906456, 32.59395161, 63.59769448, 55.86890082,\n",
       "        59.66559839, 48.53065808, 31.2809704 , 49.74959225, 51.62873801,\n",
       "        41.40113138, 48.33911938, 50.87129438, 44.35722948, 54.57679594,\n",
       "        40.97705658, 52.70666745, 49.26128484, 55.25007688, 51.21936929,\n",
       "        47.6398094 , 47.1064131 , 61.39866734, 50.5841005 , 49.40409925,\n",
       "        25.17846183, 29.05257588, 60.3936733 , 54.5134929 , 57.29888354,\n",
       "        47.20452726, 63.00311259, 54.30709531, 40.47097591, 54.81696328,\n",
       "        52.77196637, 61.32883638, 31.71515132, 51.39095558, 32.43497143,\n",
       "        63.45597454, 52.44980173, 51.16582873, 53.45231199, 47.24171307,\n",
       "        49.8813217 , 51.30468716, 39.54435194, 49.74423803, 52.29835   ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_n = (np.vstack(X_Music[:2])-mu)/std\n",
    "model.transform(np.vstack(X_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_clips(files[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data[20], rate = 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
